{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumaKori93/MasterThesisReport/blob/master/bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rmBSVaLUjie",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3ccdb4ff-48da-4761-f09f-5f63e0052412"
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "Receiving objects:   0% (1/336)   \rReceiving objects:   1% (4/336)   \rReceiving objects:   2% (7/336)   \rReceiving objects:   3% (11/336)   \rReceiving objects:   4% (14/336)   \rReceiving objects:   5% (17/336)   \rReceiving objects:   6% (21/336)   \rReceiving objects:   7% (24/336)   \rReceiving objects:   8% (27/336)   \rReceiving objects:   9% (31/336)   \rReceiving objects:  10% (34/336)   \rReceiving objects:  11% (37/336)   \rReceiving objects:  12% (41/336)   \rReceiving objects:  13% (44/336)   \rReceiving objects:  14% (48/336)   \rReceiving objects:  15% (51/336)   \rReceiving objects:  16% (54/336)   \rReceiving objects:  17% (58/336)   \rReceiving objects:  18% (61/336)   \rReceiving objects:  19% (64/336)   \rReceiving objects:  20% (68/336)   \rReceiving objects:  21% (71/336)   \rReceiving objects:  22% (74/336)   \rReceiving objects:  23% (78/336)   \rReceiving objects:  24% (81/336)   \rReceiving objects:  25% (84/336)   \rReceiving objects:  26% (88/336)   \rReceiving objects:  27% (91/336)   \rReceiving objects:  28% (95/336)   \rReceiving objects:  29% (98/336)   \rReceiving objects:  30% (101/336)   \rReceiving objects:  31% (105/336)   \rReceiving objects:  32% (108/336)   \rReceiving objects:  33% (111/336)   \rReceiving objects:  34% (115/336)   \rReceiving objects:  35% (118/336)   \rReceiving objects:  36% (121/336)   \rReceiving objects:  37% (125/336)   \rReceiving objects:  38% (128/336)   \rReceiving objects:  39% (132/336)   \rReceiving objects:  40% (135/336)   \rReceiving objects:  41% (138/336)   \rReceiving objects:  42% (142/336)   \rReceiving objects:  43% (145/336)   \rReceiving objects:  44% (148/336)   \rReceiving objects:  45% (152/336)   \rReceiving objects:  46% (155/336)   \rReceiving objects:  47% (158/336)   \rReceiving objects:  48% (162/336)   \rReceiving objects:  49% (165/336)   \rReceiving objects:  50% (168/336)   \rReceiving objects:  51% (172/336)   \rReceiving objects:  52% (175/336)   \rReceiving objects:  53% (179/336)   \rReceiving objects:  54% (182/336)   \rReceiving objects:  55% (185/336)   \rReceiving objects:  56% (189/336)   \rReceiving objects:  57% (192/336)   \rReceiving objects:  58% (195/336)   \rremote: Total 336 (delta 0), reused 0 (delta 0), pack-reused 336\u001b[K\n",
            "Receiving objects:  59% (199/336)   \rReceiving objects:  60% (202/336)   \rReceiving objects:  61% (205/336)   \rReceiving objects:  62% (209/336)   \rReceiving objects:  63% (212/336)   \rReceiving objects:  64% (216/336)   \rReceiving objects:  65% (219/336)   \rReceiving objects:  66% (222/336)   \rReceiving objects:  67% (226/336)   \rReceiving objects:  68% (229/336)   \rReceiving objects:  69% (232/336)   \rReceiving objects:  70% (236/336)   \rReceiving objects:  71% (239/336)   \rReceiving objects:  72% (242/336)   \rReceiving objects:  73% (246/336)   \rReceiving objects:  74% (249/336)   \rReceiving objects:  75% (252/336)   \rReceiving objects:  76% (256/336)   \rReceiving objects:  77% (259/336)   \rReceiving objects:  78% (263/336)   \rReceiving objects:  79% (266/336)   \rReceiving objects:  80% (269/336)   \rReceiving objects:  81% (273/336)   \rReceiving objects:  82% (276/336)   \rReceiving objects:  83% (279/336)   \rReceiving objects:  84% (283/336)   \rReceiving objects:  85% (286/336)   \rReceiving objects:  86% (289/336)   \rReceiving objects:  87% (293/336)   \rReceiving objects:  88% (296/336)   \rReceiving objects:  89% (300/336)   \rReceiving objects:  90% (303/336)   \rReceiving objects:  91% (306/336)   \rReceiving objects:  92% (310/336)   \rReceiving objects:  93% (313/336)   \rReceiving objects:  94% (316/336)   \rReceiving objects:  95% (320/336)   \rReceiving objects:  96% (323/336)   \rReceiving objects:  97% (326/336)   \rReceiving objects:  98% (330/336)   \rReceiving objects:  99% (333/336)   \rReceiving objects: 100% (336/336)   \rReceiving objects: 100% (336/336), 287.80 KiB | 8.22 MiB/s, done.\n",
            "Resolving deltas:   0% (0/184)   \rResolving deltas:   1% (3/184)   \rResolving deltas:   3% (7/184)   \rResolving deltas:   4% (8/184)   \rResolving deltas:   5% (11/184)   \rResolving deltas:   8% (15/184)   \rResolving deltas:  10% (19/184)   \rResolving deltas:  13% (24/184)   \rResolving deltas:  17% (32/184)   \rResolving deltas:  22% (41/184)   \rResolving deltas:  30% (57/184)   \rResolving deltas:  42% (78/184)   \rResolving deltas:  44% (82/184)   \rResolving deltas:  51% (94/184)   \rResolving deltas:  97% (179/184)   \rResolving deltas:  98% (182/184)   \rResolving deltas: 100% (184/184)   \rResolving deltas: 100% (184/184), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibiyhFTMUiqO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "c9c196e0-4e49-4068-fc05-417dce41b43a"
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/6c/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 118kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.17.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.5.1.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nYwAtPZUh8l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "68acc067-1633-4356-eb7f-cd54259a8f6f"
      },
      "source": [
        "!pip install gluonnlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/42/85f6cf7e13e222b2dc552059de8d37fe5956b9fab37f95dfacfa4e15a124/gluonnlp-0.8.2.tar.gz (237kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 25.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.17.5)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.2-cp36-none-any.whl size=293515 sha256=5eb35103e8c231c90ac6b0275fba2e37d000e54952eb3fdcf0c15dfa1dd23a14\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/aa/61/0aebc5c078c4b1ccf325cd7579932b99403008da6e7ce6b68f\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eNI7kdPUgi7"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import mxnet as mx\n",
        "import gluonnlp as nlp\n",
        "from bert import data, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lwxeWJSUf-w"
      },
      "source": [
        "np.random.seed(100)\n",
        "random.seed(100)\n",
        "mx.random.seed(10000)\n",
        "# change `ctx` to `mx.cpu()` if no GPU is available.\n",
        "ctx = mx.cpu(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiIz9jHxUfHi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_fjy92QUecV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "aff82d9f-f1d2-4436-e961-018debd24c76"
      },
      "source": [
        "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
        "                                             dataset_name='biobert_v1.0_pubmed_pmc_cased',\n",
        "                                             pretrained=True, ctx=ctx, use_pooler=True,\n",
        "                                             use_decoder=False, use_classifier=False)\n",
        "#print(bert_base)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab file is not found. Downloading.\n",
            "Downloading /root/.mxnet/models/1578984212.9670866biobert_v1.0_pubmed_pmc_cased-a4ff6fe1.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/biobert_v1.0_pubmed_pmc_cased-a4ff6fe1.zip...\n",
            "Downloading /root/.mxnet/models/bert_12_768_12_biobert_v1.0_pubmed_pmc_cased-8a8c7544.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_biobert_v1.0_pubmed_pmc_cased-8a8c7544.zip...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDGzYBGVUdqH"
      },
      "source": [
        "#Attach classification layer. BERTclassifier uses BERT base model to encode sentence representation\n",
        "bert_classifier = model.classification.BERTClassifier(bert_base, num_classes=3, dropout=0.1)\n",
        "# only need to initialize the classifier layer.\n",
        "bert_classifier.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
        "bert_classifier.hybridize(static_alloc=True)\n",
        "\n",
        "# softmax cross entropy loss for classification\n",
        "loss_function = mx.gluon.loss.SoftmaxCELoss()\n",
        "loss_function.hybridize(static_alloc=True)\n",
        "\n",
        "metric = mx.metric.Accuracy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqU1A9mYUc6G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "ad9b43ee-ea1c-4d1b-d681-b50681ace7a8"
      },
      "source": [
        "import io\n",
        "tsv_file = io.open('/content/test_howdo.tsv', encoding='utf-8')\n",
        "for i in range(10):\n",
        "    print(tsv_file.readline())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tRELEVANCE\tParagraph\tQuestion\n",
            "\n",
            "14049\t0\t\"&nbsp;&nbsp; Genetic factors Top Abstract Introduction Epidemiology Clinico-histopathology Genetic factors Infectious agents Experimentally induced gastric... Prospects for prevention of... Conclusions References &nbsp; Observational studies are useful to determine whether heredityplays a role in gastric cancer and molecular epidemiologicalstudies can be used to identify factors involved in cancer development,progression and metastasis. Studies aimed at determining therole of heredity in stomach cancer include family pedigree reports,twin studies, family aggregation studies and blood typing studies.As discussed by Nomura (33), it has been shown that gastriccancer can be present in families over two to three generationsand family members of a stomach cancer case have two to threetimes the risk than does the general population of developinggastric cancer. Studies involving family members are methodologicallylimited, however, because they do not distinguish genetic fromenvironmental factors, as family members tend to share a commonenvironment (33). The results of blood typing studies indicatethat blood group A is associated with gastric cancer more frequentlythan are the other blood groups. The association is strongerin males and for diffuse type gastric cancer as compared withintestinal type gastric cancer (4,33).\"\tWhat is the role of MMS2 in cancer?\n",
            "\n",
            "15939\t0\t\"Since human APC has been well characterized in terms of the domains participating in various molecular interactions and truncationsassociated with colon carcinogenesis, we also injected human APCfragments, either as recombinant protein or as synthetic mRNA(Fig.4,A andB). Unfortunately, we were unable to get efficientexpression of the full-length human APC (Fig.4D). However, fragmentsrepresenting the central part of the molecule induced an ectopicdorsoanterior axis very efficiently. 80-90% of the embryos injectedwith hAPC 2&nbsp;or hAPC 25&nbsp;in the ventral site showed a second axis(Fig.4B), many of which had complete new head structures, includinga cement gland and pigmented eyes (Fig.4C). Formation of a weakpartial secondary axis was observed in only 7% of the embryosinjected with mRNA encoding the NH2-terminal fragment hAPC 21,and the few embryos scored as positive had only very short andincomplete secondary axes. A COOH-terminal fragment hAPC3 wasalso unable to induce an ectopic dorsoanterior axis. Therefore,similar to the results withXenopus APC, the central domain ofthe human APC protein has signal transduction activity in theearlyXenopus embryo. Fragments that lack the central domain,like the NH2-terminal hAPC 21,&nbsp;which corresponds to a mutant APCfrequently observed in colon cancer, do not show this signal transductionactivity.\"\tWhat is the role of APC (adenomatous polyposis coli) in colon cancer?\n",
            "\n",
            "9131\t0\t\"The amount of TFE-CYS formed during TFE inhalation in rats andmice is not known. Hence, the blood levels of TFE and its metabolitethat were achieved during the present study are unknown. Itis almost certain, however, that the amounts of TFE-CYS givento rats and mice in this study were higher than the amountsof the metabolite formed in animals exposed to TFE. Greenetal. (1998) performed a comparative study of TFE and TFE-CYSmetabolism in rats and mice. The identity of TFE and TFE-CYSmetabolites were identical in the two species, although a quantitativeanalysis of the metabolism was not performed. Rats and miceboth metabolized TFE to difluoroacetic acid,S-(1,1,2,2-tetrafluoroethyl)-N-acetylcysteine,andN-fluoroacetylated metabolites of the cysteine conjugate.Dosing of rats and mice with TFE-CYS confirmed that all detectableTFE metabolites were formed via the cysteine conjugate. Althoughthe qualitative metabolism of TFE and TFE-CYS is identical inrats and mice, the quantitative aspects of the metabolism requirefurther study and may be an important factor in the susceptibilityof rats and mice to different tumor types when exposed to TFE.\"\tHow do interactions between HNF4 and COUP-TF1 suppress liver function?\n",
            "\n",
            "15284\t0\t\"To determine where the membrane-associated fraction of APC localizesin HCT116 cells, we used indirect immunofluorescence microscopywith the polyclonal rabbit IgG antibody N-15 raised againstan NH2-terminal peptide of human APC. Immunolocalization wascarried out on fully confluent, polarized epithelial cell monolayers.Confocal microscopic analysis of immunostained HCT116 coloncarcinoma cells showed that APC predominantly localized to theapical plasma membrane and to a very small degree to the apicolateralcell border (Fig 3, d&#150;g). APC and &#223;-catenin, forthe most part, did not colocalize. &#223;-Catenin stainingwas mostly seen laterally with very little overlap of the twoproteins detectable at the apicolateral cell borders (Fig 3g). Essentially no APC was seen in more basal sections of thecell (Fig 3 d). APC staining was most pronounced in apical sectionsof the cells (Fig 3 f). The apical localization of APC is bestobserved in the z-section of analyzed monolayers (Fig 3 g).For controls using normal mouse or rabbit IgG, no specific stainingwas detected (Fig 3, a and b). Furthermore, apical stainingof APC was effectively blocked by preincubation of the antibodieswith the neutralizing peptide against which the anti-APC antibodywas raised (Fig 3 c).\"\tWhat is the role of APC (adenomatous polyposis coli) in colon cancer?\n",
            "\n",
            "17060\t0\t\"&nbsp; Isolation of gain-of-function mutations for the cg hairpin We used the G5U/U13A and cg hairpins as baits to select forcompensating mutations in the HBP cDNA. Plasmid pAct-HBP wassubjected to random mutagenesis using hydroxylamine, amplifiedinE.coli and then used for the transformation of yeast strainL40-coat co-expressing either G5U/U13A or cgHP fusion RNA. Foreach of the hairpins, ~450 000 pAct-HBP transformants were screenedby growth on selective media lacking histidine, uracil and leucineand supplemented with 25&#160;mM 3AT. This allowed the isolationof two mutant HBP&#150;AD fusion proteins able to interactwith the cg hairpin, but none for G5U/U13A. Both of these mutations,E219K and Q208Stop, were found to interact only very weaklywith the cg hairpin (see below). To obtain mutants interactingmore strongly and also to increase the spectrum of possiblemutation types, these two plasmids were grown in the mutagenicE.coli strain XL1 red, re-isolated and used in a second roundof screening. This allowed the isolation of seven further compensatingmutations from the original mutant E219K but none from Q208Stop.Surprisingly, all the compensating mutations from both screenswere located outside the previously defined RBD (Fig.&#160;2,top), indicating that the N- and C-terminal regions of the proteinmight play a role in discriminating between natural and divergenthairpins.\"\tHow do  mutations in the Pes gene affect cell growth?\n",
            "\n",
            "1086\t0\tThe experiments presented in this article addressed the following questions:1) Can cesium induce spontaneous epileptiformactivity in hippocampal slices or in cultured hippocampal neuronsin the absence of stimulation or blockade of inhibitory systems?2) Does increasing the [K+]o mimic the effect of adding cesium?3) Does addition of cesiumchange the regulation of [K+]o?\tHow do  mutations in familial hemiplegic migraine type 1 (FHM1) gene affect calcium ion influx in hippocampal neurons?\n",
            "\n",
            "1063\t0\t\"Calcium influx does not play a role in the potentiation of ciliary ganglion nAChRs responses. This follows from the current-voltagestudies and from the ion substitution experiments. Further, theexperiments with BAPTA intracellular dialysis demonstrated thatintracellular calcium was unnecessary for the potentiation. Thecalcium concentration producing the maximal effect was close tothat expected for normal extracellular calcium levels, and otherdivalent cations such as barium and strontium (but not magnesium)readily substituted for calcium as seen for other neuronal nAChRs(Booker et al. 1998).\"\tHow do  mutations in familial hemiplegic migraine type 1 (FHM1) gene affect calcium ion influx in hippocampal neurons?\n",
            "\n",
            "1660\t0\t\"Fig. 1 compares representative traces of single channel activityat 20 and 30 mV (with 90 mM Ba2+ as charge carrier) and thei-V, po-V, andipo-V relationships obtained for the wild-typeand the S218L mutant channels. Mutation S218L did not significantlyaffect the single channel current and conductance, which was19.6 &#177; 0.2 picosiemens (n = 19) for WT and 19.2 &#177;0.3 picosiemens (n = 14) for the mutant (Fig. 1B). However,the mutation favored the sojourn of the channel in subconductancestates, which were rarely observed for the WT channel (seeinsetinFig. 1B). Moreover, the S218L mutation produced a shift ofthe single channel activation curve toward lower voltages anda consequent increase of the channel open probability in a broadvoltage range (Fig. 1C). The voltage of half-maximal activationV1/2 (obtained by fitting thepo-V relationship with a Boltzmannfunction) changed from the WT value of 34.1 &#177; 1 mV (n= 12) to 23.8 &#177; 1.8 mV (n = 10) for the mutant. Comparedwith the human FHM-1 mutants whosepo-V relationship was measuredpreviously (13,14), the S218L is one of the mutants that activatesat lower voltages (similar to those of the V714A mutant). Becausesome of the FHM-1 mutations, including V714A, decreased theunitary current and conductance, we considered the productipo(the amount of Ba2+ ions entering through a single channel ina given time,i.e. the single channel Ba2+ influx) as a measureof the gain of function produced by the FHM-1 mutations at thesingle channel level (13).Fig. 1D shows that the single channelBa2+ influx of the S218L mutant is much larger than that ofthe WT channel in a broad voltage range and similar to thatof WT at higher voltages. It also shows that the gain of functionin terms of the single channel Ba2+ influx of the S218L mutanttends to be larger than the average gain of function of thehuman FHM-1 mutants analyzed previously. The difference withrespect to the average appears significant at low voltages,where the WT human CaV2.1 channel remains closed.\"\tHow do  mutations in familial hemiplegic migraine type 1 (FHM1) gene affect calcium ion influx in hippocampal neurons?\n",
            "\n",
            "8286\t0\t\"&nbsp;&nbsp; REFERENCES TOP ABSTRACT INTRODUCTION MATERIALS AND METHODS RESULTS DISCUSSION REFERENCES &nbsp; Breitner JCS, Welsh KA. Genes and recent developments in the epidemiology of Alzheimer's disease and related dementia. Epidemiol Rev 1995;17:39&#150;47.[ISI][Medline] Strittmatter WJ, Roses AD. Apolipoprotein E and Alzheimer disease. Proc Natl Acad Sci U S A 1995;92:4725&#150;7.[Abstract] Saunders AM, Strittmatter WJ, Schmechel D, et al. Association of apolipoprotein E allele4 with late-onset familial and sporadic Alzheimer's disease. Neurology 1993;43:1467&#150;72.[Abstract] Poirier J, Davignon J, Bouthillier D, et al. Apolipoprotein E polymorphism and Alzheimer's disease. Lancet 1993;342:697&#150;9.[ISI][Medline] Corder EH, Saunders AM, Strittmatter WJ, et al. Gene dose of apolipoprotein E type 4 allele and the risk of Alzheimer's disease in late onset families. Science 1993;261:921&#150;3.[ISI][Medline] Yoshizawa T, Yamakawa-Kobayashi K, Komatsuzaki Y, et al. Dose-dependent association of apolipoprotein E allele4 with late-onset, sporadic Alzheimer's disease. Ann Neurol 1994;36:656&#150;9.[ISI][Medline] Kuusisto J, Koivisto K, Kervinen K, et al. Association of apolipoprotein E genotypes with late onset Alzheimer's disease: population based study. BMJ 1994;309:636&#150;8.[Abstract/Free Full&nbsp;Text] Nalbantoglu J, Gilfix BM, Bertrand P, et al. Predictive value of apolipoprotein E genotyping in Alzheimer's disease: results of an autopsy series and an analysis of several combined studies. Ann Neurol 1994;36:889&#150;95.[ISI][Medline] Mayers RH, Schaefer EJ, Wilson PWF, et al. Apolipoprotein E4 association with dementia in a population-based study: the Framingham Study. Neurology 1996;46:673&#150;7.[Abstract] Mak YT, Chiu H, Woo J, et al. Apolipoprotein E genotype and Alzheimer's disease in Hong Kong elderly Chinese. Neurology 1996;46:146&#150;9.[Abstract] Payami H, Zareparsi S, Montee KR, et al. Gender difference in apolipoprotein E-associated risk for familial Alzheimer disease: a possible clue to the higher incidence of Alzheimer disease in women. Am J Hum Genet 1996;58:803&#150;11.[ISI][Medline] Bickeb&ouml;ller H, Campion D, Brice A, et al. Apolipoprotein E and Alzheimer disease: genotype-specific risks by age and sex. Am J Hum Genet 1997;60:439&#150;46.[ISI][Medline] Katzman R, Zhang MY, Chen PJ, et al. Effects of apolipoprotein E on dementia and aging in the Shanghai Survey of Dementia. Neurology 1997;49:779&#150;85.[Abstract] Farrer LA, Cupples LA, Haines JL, et al. Effects of age, sex, and ethnicity on the association between apolipoprotein E genotype and Alzheimer disease: a meta-analysis. JAMA 1997;278:1349&#150;56.[Abstract] Slooter AJC, Cruts M, Kalmijn S, et al. Risk estimates of dementia by apolipoprotein E genotypes from a population-based incidence study: the Rotterdam Study. Arch Neurol 1998;55:964&#150;8.[Abstract/Free Full&nbsp;Text] Quiroga P, Calvo C, Albala C, et al. Apolipoprotein E polymorphism in elderly Chilean people with Alzheimer's disease. Neuroepidemiology 1999;18:48&#150;52.[ISI][Medline] Breitner JCS, Wyse BW, Anthony JC, et al. APOE-4 count predicts age when prevalence of AD increases, then declines: the Cache County Study. Neurology 1999;53:321&#150;31.[Abstract/Free Full&nbsp;Text] Feskens EJM, Havekes LM, Kalmijn S, et al. Apolipoprotein4 allele and cognitive decline in elderly men. BMJ 1994;309:1202&#150;6.[Abstract/Free Full&nbsp;Text] Hyman BT, Gomez-Isla T, Briggs M, et al. Apolipoprotein E and cognitive change in an elderly population. Ann Neurol 1996;40:55&#150;66.[Medline] Yaffe K, Cauley J, Sands L, et al. Apolipoprotein E phenotype and cognitive decline in a prospective study of elderly community women. Arch Neurol 1997;54:1110&#150;14.[Abstract] Jonker C, Schmand B, Lindeboom J, et al. Association between apolipoprotein E4 and the rate of cognitive decline in community-dwelling elderly individuals with and without dementia. Arch Neurol 1998;55:1065&#150;9.[Abstract/Free Full&nbsp;Text] Petersen RC, Smith GE, Ivnik RJ, et al. Apolipoprotein E status as a predictor of the development of Alzheimer's disease in memory-impaired individuals. JAMA 1995;273:1274&#150;8.[Abstract] Tierney MC, Szalai JP, Snow WG, et al. A prospective study of the clinical utility of ApoE genotype in the prediction of outcome in patients with memory impairment. Neurology 1996;46:149&#150;54.[Abstract] Evans DA, Beckett LA, Field TS, et al. Apolipoprotein E4 and incidence of Alzheimer's disease in a community population of older persons. JAMA 1997;277:822&#150;4.[Abstract] Sobel E, Louhija J, Sulkava R, et al. Lack of association of apolipoprotein E allele4 with late-onset Alzheimer's disease among Finnish centenarians. Neurology 1996;45:903&#150;7.[Abstract] Osuntokun BO, Sahota A, Ogunniyi AO, et al. Lack of an association between apolipoprotein E epsilon 4 and Alzheimer's disease in elderly Nigerians. Ann Neurol 1995;38:463&#150;5.[ISI][Medline] Tang MX, Stern Y, Marder K, et al. The APOE-4 allele and the risk of Alzheimer disease among African Americans, Whites, and Hispanics. JAMA 1998;279:751&#150;5.[Abstract/Free Full&nbsp;Text] Jarvik GP, Larson EB, Goddard K, et al. Influence of apolipoprotein E genotype on the transmission of Alzheimer disease in a community-based sample. Am J Hum Genet 1996;58:191&#150;200.[ISI][Medline] Mui S, Briggs M, Chung H, et al. A newly identified polymorphism in the apolipoprotein E enhancer gene region is associated with Alzheimer's disease and strongly with the4 allele. Neurology 1996;47:196&#150;201.[Abstract] Fratiglioni L, Viitanen M, B&ouml;ckman L, et al. Occurrence of dementia in advanced age: the study design of the Kungsholmen Project. Neuroepidemiology 1992;11(suppl 1):29&#150;36. Guo Z, Fratiglioni L, Zhu L, et al. Occurrence and progression of dementia in a community population aged 75 years and older: relationship of antihypertensive medication use. Arch Neurol 1999;56:991&#150;6.[Abstract/Free Full&nbsp;Text] Folstein MF, Folstein SE, McHugh PR. Mini-mental state: a practical method for grading the cognitive state of patients for the clinician. J Psychiatr Res 1975;12:189&#150;98.[ISI][Medline] Fratiglioni L, Grut M, Forsell Y, et al. Prevalence of Alzheimer's disease and other dementias in an elderly urban population: relationship with age, sex, and education. Neurology 1991;41:1886&#150;92.[Abstract] American Psychiatric Association. Diagnostic and statistical manual of mental disorders: DSM-III-R. 3rd ed., rev. Washington, DC: American Psychiatric Association, 1987. McKhann G, Drachman D, Folstein M, et al. Clinical diagnosis of Alzheimer's disease: report of the NINCDS-ADRDA Work Group under the auspices of Department of Health and Human Services Task Force on Alzheimer's disease. Neurology 1984;34:939&#150;44.[Abstract] Fratiglioni L, Viitanen M, von Strauss E, et al. Very old women at highest risk of dementia and Alzheimer's disease: incidence data from the Kungsholmen Project, Stockholm. Neurology 1997;48:132&#150;8.[Abstract] Guo Z, Fratiglioni L, Winblad B, et al. Blood pressure and performance on the Mini-Mental State Examination in the very old: cross-sectional and longitudinal data from the Kungsholmen Project. Am J Epidemiol 1997;145:1106&#150;13.[Abstract] Wenham PR, Price WH, Blundell G. Apolipoprotein E genotyping by one-stage PCR. Lancet 1991;337:1158&#150;9.[Medline] Basun H, Corder EH, Guo Z, et al. Apolipoprotein E polymorphism and stroke in a population sample aged 75 years or more. Stroke 1996;27:1310&#150;15.[Abstract/Free Full&nbsp;Text] Wills P, Fastbom J, Claesson CB, et al. Use of cardiovascular drugs in an older Swedish population. J Am Geriatr Soc 1996;44:54&#150;60.[ISI][Medline] Guo Z, Wills P, Viitanen M, et al. Cognitive impairment, drug use, and the risk of hip fracture in the very old: a prospective study. Am J Epidemiol 1998;148:887&#150;92.[Abstract] Guidelines for ATC classification. Uppsala, Sweden: Nordic Council on Medicines, 1985. (NLN publication no. 16). Korn EL, Graubard BI, Midthune D. Time-to-event analysis of longitudinal follow-up of a survey: choice of the time-scale. Am J Epidemiol 1997;145:72&#150;80.[Abstract] Kelsey JL, Thompson WD, Evans AS. Methods in observational epidemiology. New York, NY: Oxford University Press, 1986. Rebeck GW, Perls TT, West HL, et al. Reduced apolipoprotein4 allele frequency in the oldest old Alzheimer's patients and cognitively normal individuals. Neurology 1994;44:1513&#150;16.[Abstract] Blaker D, Haines JL, Rodes L, et al. ApoE-4 and age at onset of Alzheimer disease: the NIMH genetic initiative. Neurology 1997;48:139&#150;47.[Abstract] Kalmijn S, Feskens EJM, Launer LJ, et al. Cerebrovascular disease, the apolipoprotein e4 allele, and cognitive decline in a community-based study of elderly men. Stroke 1996;27:2230&#150;5.[Abstract/Free Full&nbsp;Text] Zhu L, Fratiglioni L, Guo Z, et al. Incidence of dementia in relation to stroke and the apolipoprotein E4 allele in the very old: findings from a population-based longitudinal study. Stroke 2000;31:751&#150;5.[Abstract/Free Full&nbsp;Text] Forette F, Seux ML, Staessen JA, et al. Prevention of dementia in randomised double-blind placebo-controlled systolic hypertension in Europe (Syst-Eur) trial. Lancet 1998;352:1347&#150;51.[ISI][Medline] Corder EH, Saunders AM, Risch NJ, et al. Protective effect of apolipoprotein E type 2 allele for late onset Alzheimer disease. Nat Genet 1994;4:180&#150;4. Guo Z, Viitanen M, Fratiglioni L, et al. Low blood pressure and dementia in elderly people: the Kungsholmen project. BMJ 1996;312:805&#150;8.[Abstract/Free Full&nbsp;Text] Received for publication July 8, 1999. Accepted for publication March 31, 2000.\"\tHow do  mutations in the Presenilin-1 gene affect Alzheimer?s disease?\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rnj9ZBCUcYT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2027c46e-420d-4c8d-a513-c08033d3ecb2"
      },
      "source": [
        "# Skip the first line, which is the schema\n",
        "# Skip the first line, which is the schema\n",
        "num_discard_samples = 1\n",
        "# Split fields by tabs\n",
        "field_separator = nlp.data.Splitter('\\t')\n",
        "#Fields to select from the file\n",
        "field_indices = [2, 3, 1]\n",
        "data_train_raw = nlp.data.TSVDataset(filename='/content/train_howdo.tsv',\n",
        "                                 field_separator=field_separator,\n",
        "                                 num_discard_samples=num_discard_samples, field_indices=field_indices)\n",
        "data_test_raw = nlp.data.TSVDataset(filename='/content/test_howdo.tsv',\n",
        "                                 field_separator=field_separator,\n",
        "                                 num_discard_samples=num_discard_samples, field_indices=field_indices)\n",
        "\n",
        "sample_id = 100\n",
        "# Sentence A\n",
        "print(data_train_raw[sample_id][0])\n",
        "# Sentence B\n",
        "print(data_train_raw[sample_id][1])\n",
        "# 1 means equivalent, 0 means not equivalent\n",
        "print(data_train_raw[sample_id][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"1. &nbsp; Arany, E, Zabel P, Freeman D, and Hill DJ. Elimination of radiolabelled recombinant human insulin-like growth factor binding protein-3 from the circulation, and its distribution amongst organs and tissues in adult male rats. Regul Pept 48: 133-143, 1993[ISI][Medline]. 2. &nbsp;\"\n",
            "How do interactions between insulin-like GFs and the insulin receptor affect skin biology?\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdHNWxh4UbB0"
      },
      "source": [
        "# Use the vocabulary from pre-trained model for tokenization\n",
        "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8i28l6nUab7"
      },
      "source": [
        "# The maximum length of an input sequence\n",
        "max_len = 128\n",
        "#  0 = not, 1 = possibly,  2=definitely\n",
        "#all_labels = ['NOT','POSSIBLY', 'DEFINITELY']\n",
        "all_labels = ['0', '1', '2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYR_roNiUZTE"
      },
      "source": [
        "pair = True\n",
        "transform = data.transform.BERTDatasetTransform(bert_tokenizer, max_len, \n",
        "                                                class_labels=all_labels,\n",
        "                                                has_label=True,\n",
        "                                                pad=True,\n",
        "                                                pair=pair)\n",
        "data_train = data_train_raw.transform(transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2goVPgTUWt8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "ca868598-899b-41cd-c84f-63dbe9a07510"
      },
      "source": [
        "\n",
        "print('valid length = \\n%s'%data_train[sample_id][1])\n",
        "print('segment ids = \\n%s'%data_train[sample_id][2])\n",
        "print('label = \\n%s'%data_train[14][3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valid length = \n",
            "112\n",
            "segment ids = \n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "label = \n",
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLYz2tJAUWH2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "84e0b03d-f51b-4c9e-f9de-ebb2465f141e"
      },
      "source": [
        "print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
        "print('%s token id = %s'%(vocabulary.padding_token, vocabulary[vocabulary.padding_token]))\n",
        "print('%s token id = %s'%(vocabulary.cls_token, vocabulary[vocabulary.cls_token]))\n",
        "print('%s token id = %s'%(vocabulary.sep_token, vocabulary[vocabulary.sep_token]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocabulary used for tokenization = \n",
            "Vocab(size=28996, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
            "[PAD] token id = 0\n",
            "[CLS] token id = 101\n",
            "[SEP] token id = 102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfwyYaXFkAjU"
      },
      "source": [
        "# The hyperparameters\n",
        "batch_size = 8\n",
        "lr = 3e-5\n",
        "decay = 1e-6\n",
        "momentum=0.9\n",
        "nesterov=True\n",
        "\n",
        "# The FixedBucketSampler and the DataLoader for making the mini-batches\n",
        "train_sampler = nlp.data.FixedBucketSampler(lengths=[int(item[1]) for item in data_train],\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True)\n",
        "bert_dataloader = mx.gluon.data.DataLoader(data_train, batch_sampler=train_sampler)\n",
        "\n",
        "trainer = mx.gluon.Trainer(bert_classifier.collect_params(), 'adam',\n",
        "                           {'learning_rate': lr, 'epsilon': 1e-9})\n",
        "#trainer = mx.gluon.Trainer(bert_classifier.collect_params(), 'sgd',\n",
        "#                           {'learning_rate': lr, 'momentum': momentum})\n",
        "\n",
        "# Collect all differentiable parameters\n",
        "# `grad_req == 'null'` indicates no gradients are calculated (e.g. constant parameters)\n",
        "# The gradients for these params are clipped later\n",
        "params = [p for p in bert_classifier.collect_params().values() if p.grad_req != 'null']\n",
        "grad_clip = 1\n",
        "\n",
        "# Training the model with only three epochs\n",
        "log_interval = 32\n",
        "num_epochs = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZfFJ1tl49ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3af9af6f-e4f2-41d7-cf50-8eb59c53ccef"
      },
      "source": [
        "for epoch_id in range(num_epochs):\n",
        "    metric.reset()\n",
        "    step_loss = 0\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(bert_dataloader):\n",
        "        with mx.autograd.record():\n",
        "\n",
        "            # Load the data to the GPU\n",
        "            token_ids = token_ids.as_in_context(ctx)\n",
        "            valid_length = valid_length.as_in_context(ctx)\n",
        "            segment_ids = segment_ids.as_in_context(ctx)\n",
        "            label = label.as_in_context(ctx)\n",
        "\n",
        "            # Forward computation\n",
        "            out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
        "            ls = loss_function(out, label).mean()\n",
        "\n",
        "        # And backwards computation\n",
        "        ls.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        trainer.allreduce_grads()\n",
        "        nlp.utils.clip_grad_global_norm(params, 1)\n",
        "        trainer.update(1)\n",
        "\n",
        "        step_loss += ls.asscalar()\n",
        "        metric.update([label], [out])\n",
        "\n",
        "        # Printing vital information\n",
        "        if (batch_id + 1) % (log_interval) == 0:\n",
        "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
        "                         .format(epoch_id, batch_id + 1, len(bert_dataloader),\n",
        "                                 step_loss / log_interval,\n",
        "                                 trainer.learning_rate, metric.get()[1]))\n",
        "            step_loss = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 Batch 32/1690] loss=0.4696, lr=0.0000300, acc=0.877\n",
            "[Epoch 0 Batch 64/1690] loss=0.4274, lr=0.0000300, acc=0.874\n",
            "[Epoch 0 Batch 96/1690] loss=0.3423, lr=0.0000300, acc=0.881\n",
            "[Epoch 0 Batch 128/1690] loss=0.3615, lr=0.0000300, acc=0.884\n",
            "[Epoch 0 Batch 160/1690] loss=0.4852, lr=0.0000300, acc=0.877\n",
            "[Epoch 0 Batch 192/1690] loss=0.4128, lr=0.0000300, acc=0.874\n",
            "[Epoch 0 Batch 224/1690] loss=0.3602, lr=0.0000300, acc=0.878\n",
            "[Epoch 0 Batch 256/1690] loss=0.2737, lr=0.0000300, acc=0.882\n",
            "[Epoch 0 Batch 288/1690] loss=0.3339, lr=0.0000300, acc=0.884\n",
            "[Epoch 0 Batch 320/1690] loss=0.3729, lr=0.0000300, acc=0.882\n",
            "[Epoch 0 Batch 352/1690] loss=0.3340, lr=0.0000300, acc=0.884\n",
            "[Epoch 0 Batch 384/1690] loss=0.3007, lr=0.0000300, acc=0.885\n",
            "[Epoch 0 Batch 416/1690] loss=0.3023, lr=0.0000300, acc=0.887\n",
            "[Epoch 0 Batch 448/1690] loss=0.2833, lr=0.0000300, acc=0.887\n",
            "[Epoch 0 Batch 480/1690] loss=0.4997, lr=0.0000300, acc=0.886\n",
            "[Epoch 0 Batch 512/1690] loss=0.2298, lr=0.0000300, acc=0.888\n",
            "[Epoch 0 Batch 544/1690] loss=0.3287, lr=0.0000300, acc=0.889\n",
            "[Epoch 0 Batch 576/1690] loss=0.4388, lr=0.0000300, acc=0.887\n",
            "[Epoch 0 Batch 608/1690] loss=0.3145, lr=0.0000300, acc=0.888\n",
            "[Epoch 0 Batch 640/1690] loss=0.3132, lr=0.0000300, acc=0.889\n",
            "[Epoch 0 Batch 672/1690] loss=0.2750, lr=0.0000300, acc=0.889\n",
            "[Epoch 0 Batch 704/1690] loss=0.3650, lr=0.0000300, acc=0.890\n",
            "[Epoch 0 Batch 736/1690] loss=0.2768, lr=0.0000300, acc=0.891\n",
            "[Epoch 0 Batch 768/1690] loss=0.2919, lr=0.0000300, acc=0.891\n",
            "[Epoch 0 Batch 800/1690] loss=0.3230, lr=0.0000300, acc=0.892\n",
            "[Epoch 0 Batch 832/1690] loss=0.2529, lr=0.0000300, acc=0.893\n",
            "[Epoch 0 Batch 864/1690] loss=0.2453, lr=0.0000300, acc=0.894\n",
            "[Epoch 0 Batch 896/1690] loss=0.1580, lr=0.0000300, acc=0.896\n",
            "[Epoch 0 Batch 928/1690] loss=0.2691, lr=0.0000300, acc=0.897\n",
            "[Epoch 0 Batch 960/1690] loss=0.2604, lr=0.0000300, acc=0.897\n",
            "[Epoch 0 Batch 992/1690] loss=0.2635, lr=0.0000300, acc=0.898\n",
            "[Epoch 0 Batch 1024/1690] loss=0.4520, lr=0.0000300, acc=0.897\n",
            "[Epoch 0 Batch 1056/1690] loss=0.3778, lr=0.0000300, acc=0.896\n",
            "[Epoch 0 Batch 1088/1690] loss=0.2225, lr=0.0000300, acc=0.898\n",
            "[Epoch 0 Batch 1120/1690] loss=0.2521, lr=0.0000300, acc=0.898\n",
            "[Epoch 0 Batch 1152/1690] loss=0.2448, lr=0.0000300, acc=0.899\n",
            "[Epoch 0 Batch 1184/1690] loss=0.2191, lr=0.0000300, acc=0.900\n",
            "[Epoch 0 Batch 1216/1690] loss=0.3168, lr=0.0000300, acc=0.900\n",
            "[Epoch 0 Batch 1248/1690] loss=0.1418, lr=0.0000300, acc=0.901\n",
            "[Epoch 0 Batch 1280/1690] loss=0.3054, lr=0.0000300, acc=0.902\n",
            "[Epoch 0 Batch 1312/1690] loss=0.3563, lr=0.0000300, acc=0.902\n",
            "[Epoch 0 Batch 1344/1690] loss=0.2949, lr=0.0000300, acc=0.902\n",
            "[Epoch 0 Batch 1376/1690] loss=0.3185, lr=0.0000300, acc=0.902\n",
            "[Epoch 0 Batch 1408/1690] loss=0.2785, lr=0.0000300, acc=0.902\n",
            "[Epoch 0 Batch 1440/1690] loss=0.2033, lr=0.0000300, acc=0.903\n",
            "[Epoch 0 Batch 1472/1690] loss=0.3727, lr=0.0000300, acc=0.903\n",
            "[Epoch 0 Batch 1504/1690] loss=0.2211, lr=0.0000300, acc=0.903\n",
            "[Epoch 0 Batch 1536/1690] loss=0.4171, lr=0.0000300, acc=0.903\n",
            "[Epoch 0 Batch 1568/1690] loss=0.3140, lr=0.0000300, acc=0.903\n",
            "[Epoch 0 Batch 1600/1690] loss=0.2060, lr=0.0000300, acc=0.903\n",
            "[Epoch 0 Batch 1632/1690] loss=0.3435, lr=0.0000300, acc=0.903\n",
            "[Epoch 0 Batch 1664/1690] loss=0.2836, lr=0.0000300, acc=0.904\n",
            "[Epoch 1 Batch 32/1690] loss=0.2044, lr=0.0000300, acc=0.938\n",
            "[Epoch 1 Batch 64/1690] loss=0.2492, lr=0.0000300, acc=0.930\n",
            "[Epoch 1 Batch 96/1690] loss=0.2466, lr=0.0000300, acc=0.928\n",
            "[Epoch 1 Batch 128/1690] loss=0.2072, lr=0.0000300, acc=0.928\n",
            "[Epoch 1 Batch 160/1690] loss=0.2210, lr=0.0000300, acc=0.931\n",
            "[Epoch 1 Batch 192/1690] loss=0.2883, lr=0.0000300, acc=0.930\n",
            "[Epoch 1 Batch 224/1690] loss=0.2878, lr=0.0000300, acc=0.928\n",
            "[Epoch 1 Batch 256/1690] loss=0.2591, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 288/1690] loss=0.2289, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 320/1690] loss=0.2694, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 352/1690] loss=0.3562, lr=0.0000300, acc=0.923\n",
            "[Epoch 1 Batch 384/1690] loss=0.1752, lr=0.0000300, acc=0.924\n",
            "[Epoch 1 Batch 416/1690] loss=0.3632, lr=0.0000300, acc=0.924\n",
            "[Epoch 1 Batch 448/1690] loss=0.2918, lr=0.0000300, acc=0.923\n",
            "[Epoch 1 Batch 480/1690] loss=0.2718, lr=0.0000300, acc=0.923\n",
            "[Epoch 1 Batch 512/1690] loss=0.1572, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 544/1690] loss=0.2849, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 576/1690] loss=0.2234, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 608/1690] loss=0.1996, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 640/1690] loss=0.2568, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 672/1690] loss=0.2443, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 704/1690] loss=0.2539, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 736/1690] loss=0.2961, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 768/1690] loss=0.1566, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 800/1690] loss=0.2782, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 832/1690] loss=0.2715, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 864/1690] loss=0.3123, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 896/1690] loss=0.2340, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 928/1690] loss=0.2521, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 960/1690] loss=0.2143, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 992/1690] loss=0.2622, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1024/1690] loss=0.1966, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1056/1690] loss=0.2597, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1088/1690] loss=0.1575, lr=0.0000300, acc=0.927\n",
            "[Epoch 1 Batch 1120/1690] loss=0.2468, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1152/1690] loss=0.2518, lr=0.0000300, acc=0.927\n",
            "[Epoch 1 Batch 1184/1690] loss=0.2280, lr=0.0000300, acc=0.927\n",
            "[Epoch 1 Batch 1216/1690] loss=0.3009, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1248/1690] loss=0.2172, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1280/1690] loss=0.2521, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1312/1690] loss=0.2162, lr=0.0000300, acc=0.927\n",
            "[Epoch 1 Batch 1344/1690] loss=0.3258, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1376/1690] loss=0.2681, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1408/1690] loss=0.3011, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1440/1690] loss=0.2826, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 1472/1690] loss=0.2517, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 1504/1690] loss=0.2359, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1536/1690] loss=0.2549, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 1568/1690] loss=0.2569, lr=0.0000300, acc=0.925\n",
            "[Epoch 1 Batch 1600/1690] loss=0.2521, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1632/1690] loss=0.3007, lr=0.0000300, acc=0.926\n",
            "[Epoch 1 Batch 1664/1690] loss=0.2648, lr=0.0000300, acc=0.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9t0utFKzkCQ"
      },
      "source": [
        "#Run test_set\n",
        "data_test = data_test_raw.transform(transform)\n",
        "test_dataloader = mx.gluon.data.DataLoader(data_test, batch_size=batch_size, shuffle=False, last_batch='rollover')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rVa3-B8rIvr"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score, zero_one_loss\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "\n",
        "def print_results(y_true, y_pred):\n",
        "    print(\"Error Rate: {:2.2f}\".format(100*zero_one_loss(y_true, y_pred)))\n",
        "    print(\"Accuracy: {:2.2f}\".format(100*accuracy_score(y_true, y_pred)))\n",
        "    print(\"F1-Score: {:2.2f}\".format(100*f1_score(y_true, y_pred, average=\"weighted\")))\n",
        "    print(\"Precision: {:2.2f}\".format(100*precision_score(y_true, y_pred, average=\"weighted\")))\n",
        "    print(\"Recall: {:2.2f}\".format(100*recall_score(y_true, y_pred, average=\"weighted\")))\n",
        "    #fig, ax = plt.subplots(figsize=(18, 10))\n",
        "    #x = sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, ax=ax)\n",
        "    #x.invert_yaxis()\n",
        "    #plt.xlabel(\"Predicted\")\n",
        "    #plt.ylabel(\"True\")\n",
        "    #return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsTPo3Haktsp"
      },
      "source": [
        "from mxnet import gluon, nd, autograd\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "    token_ids = token_ids.as_in_context(ctx)\n",
        "    valid_length = valid_length.as_in_context(ctx)\n",
        "    segment_ids = segment_ids.as_in_context(ctx)\n",
        "    label = label.as_in_context(ctx)\n",
        "    out = bert_classifier(token_ids, segment_ids, valid_length.astype('float32'))\n",
        "    pred = nd.argmax(out, axis=1).asnumpy()\n",
        "    y_true.extend(list(np.reshape(label.asnumpy(), (-1))))\n",
        "    y_pred.extend(pred)\n",
        "assert len(y_true)==len(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaYW5izu9G7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "8a3b26eb-0196-4baa-8590-26def471e1c9"
      },
      "source": [
        "fig = print_results(np.reshape(y_true, (-1)), y_pred)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred))\n",
        "print(confusion_matrix(y_true,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error Rate: 8.17\n",
            "Accuracy: 91.83\n",
            "F1-Score: 91.49\n",
            "Precision: 91.20\n",
            "Recall: 91.83\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      2991\n",
            "           1       0.42      0.34      0.37       157\n",
            "           2       0.65      0.60      0.63       220\n",
            "\n",
            "    accuracy                           0.92      3368\n",
            "   macro avg       0.68      0.64      0.65      3368\n",
            "weighted avg       0.91      0.92      0.91      3368\n",
            "\n",
            "[[2907   41   43]\n",
            " [  75   53   29]\n",
            " [  55   32  133]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}